verboseIter = TRUE,
classProbs = TRUE)
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE,
classProbs = TRUE)
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE,
classProbs = TRUE)
method = 'mlpKerasDecayCost'
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE,
classProbs = TRUE)
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
Y
?install_tensorflow
install_tensorflow
install_tensorflow()
library(tensorflow)
library(keras)
library(tensorflow)
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
# method = 'mlpKerasDecayCost'
method = 'pcaNNet'
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
xytrain$class
?train
library(caret)
library(caret)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
xytrain$class
xytrain %>% select(-class) %>% as.matrix
## training
fit <- train(
x = xytrain %>% select(-class), # %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
xytrain %>% select(-class) %>% as.matrix
xytrain %>% select(-class) %>% as.matrix %>% colnames
##################################################
# Author: Daniel Durrenberger
# Company: Dataiku
# Object: Test
# Date: 05.03.2020
#
######################################
library(tidyverse)
library(dplyr)
library(dbplyr)
library(xgboost)
library(tibble)
library(ggplot2)
library(pROC)
library(earth)
library(nnet)
library(rocc)
library(caret)
# Project metadata
method = 'xgbTree'
# method = 'mlpKerasDecayCost'
method = 'nnet'
# method = 'rocc'
# Files
trainFile <- "./data/census_income_learn.csv"
testFile <- './data/census_income_test.csv'
# Load Files
trainDataRaw <- read.csv(file = trainFile, header = FALSE) %>% as.tibble
testDataRaw <- read.csv(file = testFile, header = FALSE) %>% as.tibble
trainDataRaw %>% head #See what it looks like
# Clean data
## Convert all non numeric into dummy variables and keep numerics unchanged
customPreprocess2 <- function(trainDataRaw) {
trainDataClean <- trainDataRaw %>%
mutate(class = if_else(as.numeric(V42)==2, 'over50', 'below50') %>% factor) %>%
select(-V42) %>%
as.tibble
dummies <- dummyVars(class ~ ., data = trainDataClean)
trainDataDummies <- predict(dummies, newdata = trainDataClean) %>%
as.tibble
trainDataDummies$class = trainDataClean$class %>% factor
trainDataDummies
}
allData <- bind_rows(
trainDataRaw %>% mutate(train = 1),
testDataRaw %>% mutate(train = 0)) %>%
customPreprocess2
# Remove columns with near zero variance.
nzv <- nearZeroVar(allData)
allData <- allData[,-nzv]
allData %>% head #See result
# Split data
## One half of training set is used to train
xytrain <- allData %>%
filter(train == 1) %>%
select(-train) %>%
group_by(class) %>%
sample_frac(.5) %>%
ungroup
## The other half for calibration
xycal <- allData %>%
filter(train == 1) %>%
select(-train) %>%
anti_join(xytrain) %>%
ungroup
## Test set is left untouched
xytest <- allData %>%
filter(train == 0) %>%
select(-train) %>%
ungroup
## Check class balance
xytrain$class %>% summary
xycal$class %>% summary
xytest$class %>% summary
xytrain %>% dim
# Train Model
## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE)
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 1,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
# Results
## Training performance
fit$results %>% arrange(-ROC) %>% head
## Importance of variables
varImp(fit, scale = TRUE)
# Calibration
calPredict <- predict(fit,
newdata = xycal %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .8, 'below50', 'over50') %>% factor) %>%
mutate(obs = xycal$class %>% factor)
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
confusionMatrix(calPredict$obs, calPredict$pred)
# Calibration
calPredict <- predict(fit,
newdata = xycal %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .8, 'below50', 'over50') %>% factor) %>%
mutate(obs = xycal$class %>% factor)
calPredict
# Calibration
calPredict <- predict(fit,
newdata = xycal %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .5, 'below50', 'over50') %>% factor) %>%
mutate(obs = xycal$class %>% factor)
plot(pROC_obj_cal)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
confusionMatrix(calPredict$obs, calPredict$pred)
# Project metadata
method = 'xgbTree'
## training
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 5,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
# Results
## Training performance
fit$results %>% arrange(-ROC) %>% head
## Importance of variables
varImp(fit, scale = TRUE)
# Results
## Training performance
fit$results %>% arrange(-ROC) %>% head
# Calibration
calPredict <- predict(fit,
newdata = xycal %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .5, 'below50', 'over50') %>% factor) %>%
mutate(obs = xycal$class %>% factor)
threshold <- 0.5
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
threshold <- 0.8
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
threshold <- 0.6
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
# Test
testPredict <- predict(fit,
newdata = xytest %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .8, 'below50', 'over50') %>% factor) %>%
mutate(obs = xytest$class %>% factor)
testPredict <- testPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(testPredict$obs, testPredict$pred)
pROC_obj_cal <- roc(testPredict$obs, testPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
saveRDS(fit, file = 'model_xgboost.RData')
source('~/Workplace/R/dataiku/src/explore.R', echo=TRUE)
saveRDS(fit, file = 'model_nn.RData')
## Save training
saveRDS(fit, file = 'model_nn.RData')
## Importance of variables
varImp(fit, scale = TRUE)
calPredict
threshold <- 0.1
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
calPredict
threshold <- 0.8
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
confusionMatrix(calPredict$obs, calPredict$pred)
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
fit
source('~/Workplace/R/dataiku/src/explore.R', echo=TRUE)
############# Set threshold using ROC curve
threshold <- 0.65
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
######################## Test
############################# Test set consist of untouched data, independant to training
############################# or calibration to assess the behavior the model with
############################# new unknown data
########### Predict test set with chosen threshold
testPredict <- predict(fit,
newdata = xytest %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor) %>%
mutate(obs = xytest$class %>% factor)
########### See confusion matrix
confusionMatrix(testPredict$obs, testPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.5
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.8
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
######################## Test
############################# Test set consist of untouched data, independant to training
############################# or calibration to assess the behavior the model with
############################# new unknown data
########### Predict test set with chosen threshold
testPredict <- predict(fit,
newdata = xytest %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor) %>%
mutate(obs = xytest$class %>% factor)
############# Set threshold using ROC curve
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.75
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.78
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.65
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.67
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
######################## Test
############################# Test set consist of untouched data, independant to training
############################# or calibration to assess the behavior the model with
############################# new unknown data
########### Predict test set with chosen threshold
testPredict <- predict(fit,
newdata = xytest %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor) %>%
mutate(obs = xytest$class %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
############# Set threshold using ROC curve
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
source('~/Workplace/R/dataiku/src/explore.R', echo=TRUE)
method = 'nnet'
#################### Train Model
######################## Settings
fitControl <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 1,
summaryFunction = twoClassSummary,
classProbs = TRUE,
verboseIter = TRUE)
######################## Training
if (trainAgain) {
fit <- train(
x = xytrain %>% select(-class) %>% as.matrix,
y = xytrain$class,
tuneLength = 5,
method = method,
trControl = fitControl,
metric = 'ROC',
verbose = TRUE
)
fit$results %>% arrange(-ROC) %>% head
saveRDS(fit, file = 'model_new.RData')
}
######################## Importance of variables
############################ Here feature names are not helping,
############################ but usually, it is a very safe way to evaluate the model
############################ as the most important vars should be known and studied
varImp(fit, scale = TRUE)
######################## Calibration
############################# The aim in this section is to set the threshold
############################# between both of the classes. The defaut 0.5 probability
############################# may not be the best choice. The decision should be taken
############################# considering kappa, sensitivity, specificity, ROC curve
############################# Accuracy should not be considered as the dataset is imbalanced
######## Predict calibration set
calPredict <- predict(fit,
newdata = xycal %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > .5, 'below50', 'over50') %>% factor) %>%
mutate(obs = xycal$class %>% factor)
############ ROC curve for calibration set
pROC_obj_cal <- roc(calPredict$obs, calPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
############# Set threshold using ROC curve
threshold <- 0.7
calPredict <- calPredict %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor)
############# See confusion matrix with set threshold
confusionMatrix(calPredict$obs, calPredict$pred)
######################## Test
############################# Test set consist of untouched data, independant to training
############################# or calibration to assess the behavior the model with
############################# new unknown data
########### Predict test set with chosen threshold
testPredict <- predict(fit,
newdata = xytest %>% select(-class) %>% as.matrix,
type = 'prob') %>%
mutate(pred = if_else(below50 > threshold, 'below50', 'over50') %>% factor) %>%
mutate(obs = xytest$class %>% factor)
########### See confusion matrix
confusionMatrix(testPredict$obs, testPredict$pred)
########### and ROC curve
pROC_obj_cal <- roc(testPredict$obs, testPredict$below50, ci = TRUE)
pROC_obj_cal
plot(pROC_obj_cal)
